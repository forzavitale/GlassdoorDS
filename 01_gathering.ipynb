{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Glassdoor.com:  'Data Scientist' Job Search\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Get all 'data scientist' results from past 14 days for full-time positions located in NYC with salary info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "focus": false,
    "id": "2efefc73-064a-482d-b3b5-ddf5508cb4ec"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime as dt\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import re\n",
    "import json\n",
    "from random import randint\n",
    "from scipy.stats import gaussian_kde\n",
    "import matplotlib.pyplot as plt\n",
    "import html\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_links(URL):\n",
    "    '''Collect individual links for relevant search results.'''\n",
    "    chromedriver = ''.join([os.getcwd(), '/chromedriver'])\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(executable_path = chromedriver)\n",
    "    try:\n",
    "        driver.set_page_load_timeout(60)\n",
    "        driver.get(URL)\n",
    "        soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "        listy = []\n",
    "        for x in soup.find_all('a', class_ = 'jobLink', href = re.compile('/partner/jobListing')):\n",
    "            full_x = ''.join(['http://www.glassdoor.com', x['href']])\n",
    "            listy.append(full_x)        \n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "    except TimeoutException: \n",
    "        ## try/exc is workaround, see https://bit.ly/2umrGrq\n",
    "        try:\n",
    "            driver.close()\n",
    "        except:\n",
    "            pass\n",
    "        driver.quit() \n",
    "        print(URL)\n",
    "        listy = None\n",
    "    return listy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-22 15:23:49.059477\n",
      ".....................\n",
      "elapsed: 0:03:26.567977\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.glassdoor.com/partner/jobListing.ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.glassdoor.com/partner/jobListing.ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.glassdoor.com/partner/jobListing.ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://www.glassdoor.com/partner/jobListing.ht...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://www.glassdoor.com/partner/jobListing.ht...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url\n",
       "0  http://www.glassdoor.com/partner/jobListing.ht...\n",
       "2  http://www.glassdoor.com/partner/jobListing.ht...\n",
       "4  http://www.glassdoor.com/partner/jobListing.ht...\n",
       "6  http://www.glassdoor.com/partner/jobListing.ht...\n",
       "8  http://www.glassdoor.com/partner/jobListing.ht..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = dt.now()\n",
    "print(start)\n",
    "\n",
    "base_url = [\n",
    "    'https://www.glassdoor.com/Job/new-york-data-scientist-jobs-SRCH_IL.0,8_IC1132348_KO9,23_IP', \n",
    "    '.htm?radius=0&fromAge=14&minSalary=26000&jobType=fulltime'\n",
    "]\n",
    "\n",
    "count = 1\n",
    "all_links = []\n",
    "switch = False\n",
    "while switch == False:\n",
    "    time.sleep(1 + 1/randint(1, 3))\n",
    "    URL = ''.join([base_url[0], str(count), base_url[1]])\n",
    "    new_list = get_links(URL)\n",
    "    if new_list:\n",
    "        all_links.extend(new_list)\n",
    "        print('.', end = '')\n",
    "        count += 1\n",
    "    else:\n",
    "        switch = True \n",
    "        \n",
    "end = dt.now()\n",
    "print('\\nelapsed: {}'.format(end - start))\n",
    "\n",
    "df = pd.DataFrame(all_links, columns = ['url'])\n",
    "df.drop_duplicates(inplace = True)\n",
    "df.to_csv('assets/links.csv', index = False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1301\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('assets/links.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unescape(s):\n",
    "    '''Unescape some HTML to get rid of tags, etc.'''\n",
    "    s = s.replace(\"\\&amp;#034;\", \"\\'\")\n",
    "    s = s.replace(\"&amp;#034;\", \"\\'\")\n",
    "    s = s.replace(\"&amp;\", \"&\")\n",
    "    s = s.replace(\"&lt;\", \"<\")\n",
    "    s = s.replace(\"&gt;\", \">\")\n",
    "    s = s.replace(\"\\\\\", \" \")\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def listing_parts(soup):\n",
    "    '''Get listing info from scrape output.'''\n",
    "    \n",
    "    x = soup.find('script', {'type' : 'application/ld+json'}).text\n",
    "    xx = x.encode().replace(b'\\n', b'').replace(b'\\t', b'').decode('utf-8')\n",
    "    xxx = BeautifulSoup(unescape(xx), 'lxml').get_text(' ')\n",
    "    info_dict = json.loads(xxx)\n",
    "    \n",
    "    ## title\n",
    "    try:\n",
    "        title = info_dict[\"title\"]\n",
    "    except:\n",
    "        title = np.nan\n",
    "        \n",
    "    ## datePosted\n",
    "    try:\n",
    "        dateposted = info_dict[\"datePosted\"]\n",
    "    except:\n",
    "        dateposted = np.nan\n",
    "        \n",
    "    ## validthrough\n",
    "    try:\n",
    "        validthrough = info_dict['validThrough']\n",
    "    except:\n",
    "        validthrough = np.nan\n",
    "        \n",
    "    ## industry\n",
    "    try:\n",
    "        industry = info_dict['industry']\n",
    "    except:\n",
    "        industry = np.nan\n",
    "        \n",
    "    ## organization name\n",
    "    try:\n",
    "        orgname = info_dict['hiringOrganization']['name']\n",
    "    except:\n",
    "        orgname = np.nan\n",
    "        \n",
    "    ## category\n",
    "    try:\n",
    "        cat = info_dict['occupationalCategory']\n",
    "    except:\n",
    "        cat = np.nan\n",
    "    \n",
    "    ## description\n",
    "    try:\n",
    "        descr = info_dict['description']\n",
    "    except:\n",
    "        descr = np.nan\n",
    "    \n",
    "    ## stars\n",
    "    stars = np.nan\n",
    "    for x in soup.findAll('span', class_ = 'compactStars margRtSm'):\n",
    "        stars = float((x.text).lstrip().rstrip())\n",
    "    \n",
    "    ## salary\n",
    "    jobid = np.nan\n",
    "    minsal = np.nan\n",
    "    maxsal = np.nan\n",
    "    medsal = np.nan\n",
    "    empid = np.nan\n",
    "    jobtitleid = np.nan\n",
    "    jobreqid = np.nan \n",
    "    \n",
    "    for x in soup.findAll('i', {'class' : 'info infoSalEst _ok'}):\n",
    "        try:\n",
    "            jobid = x['data-job-id']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            minsal = x['data-displayed-min-salary']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            maxsal = x['data-displayed-max-salary']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            medsal = x['data-displayed-med-salary']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            empid = x['data-employer-id']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            jobtitleid = x['data-jobtitle-id']\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            jobreqid = x['data-job-req-id']\n",
    "        except:\n",
    "            pass  \n",
    "        \n",
    "    listy = [\n",
    "        title,\n",
    "        dateposted,\n",
    "        validthrough,\n",
    "        industry,\n",
    "        orgname,\n",
    "        cat,\n",
    "        descr,\n",
    "        stars,\n",
    "        jobid,\n",
    "        minsal,\n",
    "        maxsal,\n",
    "        medsal,\n",
    "        empid,\n",
    "        jobtitleid,\n",
    "        jobreqid\n",
    "    ]\n",
    "    lil_df = pd.DataFrame(listy)\n",
    "    return lil_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_listing(URL):\n",
    "    '''Collect individual job posting info.'''\n",
    "    chromedriver = ''.join([os.getcwd(), '/chromedriver'])\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(executable_path = chromedriver)\n",
    "    try:\n",
    "        driver.set_page_load_timeout(60)\n",
    "        driver.get(URL)\n",
    "        soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "        result = listing_parts(soup)       \n",
    "        driver.close()\n",
    "        driver.quit()\n",
    "    except Exception as e: \n",
    "        print('\\nposs expired listing: {}'.format(str(e)))\n",
    "        ## try/exc is workaround, see https://bit.ly/2umrGrq\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            driver.close()\n",
    "        except Exception as e:\n",
    "            print('get_listing 2: {}'.format(str(e)))\n",
    "        driver.quit() \n",
    "        result = None\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-22 15:27:16.010025\n",
      "1301\n",
      "0.........100.........200.........300.........400.........500.........600.........700.........800.........900.........1000.........\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      "1100...\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      "....\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      "..1200\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      ".....\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      "\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      "...\n",
      "poss expired listing: 'NoneType' object has no attribute 'text'\n",
      "url loop: 'NoneType' object has no attribute 'T'\n",
      ".13001294\n",
      "\n",
      " 606\n",
      "\n",
      "elapsed: 3:20:49.230192\n"
     ]
    }
   ],
   "source": [
    "start = dt.now()\n",
    "print(start)\n",
    "\n",
    "big_df = pd.DataFrame()\n",
    "urls = []\n",
    "skipped = []\n",
    "count = 0\n",
    "print(len(df))\n",
    "for url in df['url']:\n",
    "    time.sleep(1/randint(1,3) + 5/randint(1, 5))\n",
    "    try:\n",
    "        lil_df = get_listing(url).T\n",
    "        big_df = pd.concat([big_df, lil_df], axis = 0)\n",
    "        urls.append(url)\n",
    "    except Exception as e:\n",
    "        skipped.append(url)\n",
    "        print('url loop: {}'.format(str(e)))\n",
    "    if count%100 == 0:\n",
    "        print(count, end = '')\n",
    "    elif count%10 == 0:\n",
    "        print('.', end = '')\n",
    "    count += 1\n",
    "        \n",
    "big_df.columns = [\n",
    "    'title',\n",
    "    'dateposted',\n",
    "    'validthrough',\n",
    "    'industry',\n",
    "    'orgname',\n",
    "    'cat',\n",
    "    'descr',\n",
    "    'stars',\n",
    "    'jobid',\n",
    "    'minsal',\n",
    "    'maxsal',\n",
    "    'medsal',\n",
    "    'empid',\n",
    "    'jobtitleid',\n",
    "    'jobreqid'\n",
    "]\n",
    "\n",
    "big_df['url'] = urls\n",
    "print(len(big_df))\n",
    "big_df.head(2)\n",
    "big_df.drop_duplicates(subset = ['jobid', 'validthrough', 'title'], inplace = True)\n",
    "print('\\n', len(big_df))\n",
    "big_df.to_csv('assets/glassdoor_22april2018.csv', index = False)\n",
    "\n",
    "end = dt.now()\n",
    "print('\\nelapsed: {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.glassdoor.com/partner/jobListing.htm?pos=1802&ao=186496&s=58&guid=00000162eed27352bbfa14c228bc2031&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&rtp=0&cs=1_fe90273d&cb=1524425192937&jobListingId=2739078444',\n",
       " 'http://www.glassdoor.com/partner/jobListing.htm?pos=1802&ao=186496&s=58&guid=00000162eed27352bbfa14c228bc2031&src=GD_JOB_AD&vt=w&rtp=0&cs=1_fe90273d&cb=1524425192985&jobListingId=2739078444',\n",
       " 'http://www.glassdoor.com/partner/jobListing.htm?pos=1914&ao=175631&s=58&guid=00000162eed2985d9e63456f8a1ffb17&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&rtp=0&cs=1_8805b47a&cb=1524425202470&jobListingId=2728429085',\n",
       " 'http://www.glassdoor.com/partner/jobListing.htm?pos=1914&ao=175631&s=58&guid=00000162eed2985d9e63456f8a1ffb17&src=GD_JOB_AD&vt=w&rtp=0&cs=1_8805b47a&cb=1524425202502&jobListingId=2728429085',\n",
       " 'http://www.glassdoor.com/partner/jobListing.htm?pos=2026&ao=186496&s=58&guid=00000162eed2bfe993875553ca0f76c5&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&rtp=0&cs=1_2b74984b&cb=1524425212616&jobListingId=2734570887',\n",
       " 'http://www.glassdoor.com/partner/jobListing.htm?pos=2026&ao=186496&s=58&guid=00000162eed2bfe993875553ca0f76c5&src=GD_JOB_AD&t=SR&extid=1&exst=OL&ist=&ast=OL&vt=w&slr=true&rtp=0&cs=1_2b74984b&cb=1524425212617&jobListingId=2734570887',\n",
       " 'http://www.glassdoor.com/partner/jobListing.htm?pos=2026&ao=186496&s=58&guid=00000162eed2bfe993875553ca0f76c5&src=GD_JOB_AD&vt=w&rtp=0&cs=1_2b74984b&cb=1524425212627&jobListingId=2734570887']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skipped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
